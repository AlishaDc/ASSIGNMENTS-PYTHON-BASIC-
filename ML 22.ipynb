{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315c1509",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "\n",
    "Try combining them into a voting ensemble, which will often give you even better results. It works better if the models are very different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f8d67",
   "metadata": {},
   "source": [
    "# Q2. \n",
    "\n",
    "In hard voting (also known as majority voting), every individual classifier votes for a class, and the majority wins. In statistical terms, the predicted target label of the ensemble is the mode of the distribution of individually predicted labels. In soft voting, every individual classifier provides a probability value that a specific data point belongs to a particular target class. The predictions are weighted by the classifier's importance and summed up. Then the target label with the greatest sum of weighted probabilities wins the vote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df290f8a",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "If you want to speed up your bagging then instead of distribution you should reduce the size of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7cc583",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "The advantage of evaluating out of bag are that the model is never trained on the that data so it is used for evaluating the accuracy of the model. so,we do not need of cross validation and can use out of bag instance for that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a9d94",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "Random forest uses bootstrap replicas, that is to say, it subsamples the input data with replacement, whereas Extra Trees use the whole original sample. This may increase variance because bootstrapping makes it more diversified.\n",
    "\n",
    "In terms of computational cost, and therefore execution time, the Extra Trees algorithm is faster. This algorithm saves time because the whole procedure is the same, but it randomly chooses the split point and does not calculate the optimal one.\n",
    "\n",
    "Moreover, as expected, Extra Trees is much faster. This is because instead of looking for the optimal split at each node it does it randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c2f8e",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "Try increasing the number of estimators or reducing the regularization hyperparameters of the base estimator, also try slightly increasing the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56519fdb",
   "metadata": {},
   "source": [
    "# Q7.\n",
    "Decreasing the learning rate, early stopping to find the right number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1cdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
