{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1bc01cd",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "\n",
    "\n",
    "Supervised machine learning is a method of solving machine learning problems by training a machine learning model using a labelled data. Labelled data would mean that for every nth set of values for i number of independent variables, a value x would be present belonging to the dependent variable where, value of x can belong to countably finite or uncountably infinite set.\n",
    "\n",
    "Significance of the name is that the name itself explains that there will be some form of supervision working on machine learning. The labelled data acts as a supervision for machine learning as class labels or target variable values have been manually fed or generated from past records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8b9be",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "\n",
    "Several surgeries and therapies like chemotherapy are last resort method to patients debilitating them. These surgeries often run a risk of death if a combination of parameters like oxygen saturation level are not within limits. Crucial time is saved by feeding the patient's readings against such parameters into supervised machine learning models that can classify the survivability of a patient post surgery fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d99de7",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "\n",
    "1. Sentiment Analysis on a product's reviews to determine how well the product is doing on an e-commerce platform.\n",
    "2. Spam detection to remove e-mails that are advertising based.\n",
    "3. Prediction of salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a4a91",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "\n",
    "Classification is a task performed using supervised learning where the target or dependent variable values in the labelled data come from a countably finite set.\n",
    "\n",
    "Regression is a task performed using supervised learning where the target or dependent variable values in the labelled data come from a countably infinite set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68e22a",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "\n",
    "1. Naive Bayes classifier\n",
    "\n",
    "2. Random Forest classifier\n",
    "\n",
    "3. Support Vector classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961afda1",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "\n",
    "SVM or Support Vector Machine model is a machine learning model that can be used for classification and regression model. It relies on finding a hyperplane and support vectors for classification such that the two data points on the outskirts of their own classes of linearly classifiable data. These support vectors act as margins on either side of the hyperplane. Support vectors are chosen such that the margin on either side of hyperplane is maximum.\n",
    "\n",
    "Support Vector Machine models are not only used for binary linear classification, but can also be used for multiclass non linear classification. Support Vector algorithms use kernels like polynomial kernels, quadratic kernels, string kernels and genome kernels for kernelization which is just like feature transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eaaf5",
   "metadata": {},
   "source": [
    "# Q7.\n",
    "\n",
    "Zeta is the variable that becomes the cost of misclassification. Its value is determined by the distance of a misclassified point beyond or inside a margin. 0 value of zeta would mean correct classification while a non zero value would mean misclassification on one side of the main hyperplane.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9a558",
   "metadata": {},
   "source": [
    "# Q8.\n",
    "\n",
    "In SVM model, the hyperplane is calculated such that it maximises the margin(margin is set such that one margin touches data point of one class and one margin touches data point of another class) or maximises the distance between hyperplane and margin and classifies the data points as widely as possible.\n",
    "\n",
    "These margin calculations are done by setting margin only those data points that face the hyperplane and belong to different class. Such data points that can be set as margin to maximise the distance between hyperplane and margin and classifies the data points as widely as possible will be known as support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a0956",
   "metadata": {},
   "source": [
    "# Q9.\n",
    "\n",
    "In the SVM model, different mathematical functions can be used in place of the (transpose(xi)*x) of the dual problem for various implicit feature transformations. Such mathematical functions that can make SVM work with nearly any form of non linear classification and regression is called the kernel. For example, String kernels can be used to make SVM usable for NLP applications.\n",
    "\n",
    "f(x)=N Xi Î±i yi (xiTx) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aebf42",
   "metadata": {},
   "source": [
    "# Q10.\n",
    "\n",
    "Dimensionality, value of C and kernel used are the 3 factors that influence SVM's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b97f14",
   "metadata": {},
   "source": [
    "# Q11.\n",
    "\n",
    "1. Works well with high dimensionality.\n",
    "\n",
    "2. Outliers have little impact in case of kernel SVMs.\n",
    "\n",
    "3. Implicit kernelization helps SVM work and come up with non linear decision surfaces.\n",
    "\n",
    "4. High generalizability due to margins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c11b6",
   "metadata": {},
   "source": [
    "# Q12.\n",
    "\n",
    "Finding or coming up with problem specific kernels for best performance of SVM is difficult.\n",
    "\n",
    "No inherent way of getting feature importance.\n",
    "\n",
    "Built model has low interpretability\n",
    "\n",
    "Presence of two hyperparameters makes tuning time large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efb3f2",
   "metadata": {},
   "source": [
    "# Q13.\n",
    "\n",
    "# Notes should be written on\n",
    "# A. The kNN algorithm has a validation flaw.\n",
    "# B. In the kNN algorithm, the k value is chosen.\n",
    "k is a hyperparameter in the KNN algorithm where k is the number of clusters that will be made. Optimal k value can be found using the elbow method in which, the performance of the clustering algorithm is measured against the values of k.\n",
    "\n",
    "# C. A decision tree with inductive bias\n",
    "The inductive bias in decision tree is that shorter trees are preferred over longer trees. Smaller trees would mean smaller depths with small number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f4ed8",
   "metadata": {},
   "source": [
    "# Q14.\n",
    "\n",
    "Built model is easy to interpret.\n",
    "\n",
    "Time and Space complexity low.\n",
    "\n",
    "Train time is virtually none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc38f4",
   "metadata": {},
   "source": [
    "# Q15.\n",
    "Sensitive to outliers.\n",
    "\n",
    "Does not work well with high dimensionality.\n",
    "\n",
    "Sensitive to missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9c08f",
   "metadata": {},
   "source": [
    "# Q16.\n",
    "\n",
    "Decision Tree algorithm is a supervised machine learning algorithm where an inverted tree is created and data is split into nodes based on a threshold or condition passed or failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bdc33",
   "metadata": {},
   "source": [
    "# Q17.\n",
    "\n",
    "Node in a decision tree is a collection of data points for which decision has to be made whether to split or not, and how to split using a mathematical function.\n",
    "\n",
    "Leaf in a decision tree is a terminating node or a terminating vector, beyond which no splits will be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460a92",
   "metadata": {},
   "source": [
    "# Q18.\n",
    "\n",
    "Entropy is the measure of a purity or homogenity of a sample of data points. Using entropy, the best split of sample can be calculated.\n",
    "\n",
    "Maximum entropy is 1 and is calculated for sample of data that would have 50-50% class label data points. Minimum entropy is 0 and is calculated for sample of data that would have 0% data points for class label 1 but 100% data points for class label 2, meaning that it will not be split further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919ff94",
   "metadata": {},
   "source": [
    "# Q19.\n",
    "\n",
    "Numerical value used to quantify the quality of a split is called knowledge gain or information gain. It is calculated by subtracting the weighted entropies for each branch from the original entropy. Maximising information gain leads to best results in decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d7696",
   "metadata": {},
   "source": [
    "# Q20.\n",
    "\n",
    "1. A function in the form of gini index is used and solved for getting mathematically sound splits and end classification.\n",
    "2. Decision Trees can be visually realized, and have high interpretability.\n",
    "3. Decision Tree approach is not distance based, only based on order and logic. Due to this, many preprocessing methods need not be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0888d",
   "metadata": {},
   "source": [
    "# Q21.\n",
    "\n",
    "1. Decision Trees are inherently overfitting.\n",
    "2. They do not perform well for high dimensional data.\n",
    "3. Training an accurate model for continous data is difficult as little changes in the training data would lead to different results in classification on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d971dc",
   "metadata": {},
   "source": [
    "# Q22.\n",
    "\n",
    "Random forest model is an aggregation ensemble model technique based on decision trees. Multiple base learner decision trees are trained on subsets of data and each comes up with its own classification result. At the end, a majority vote is used to come to the final conclusion regarding the true classification result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ed2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
